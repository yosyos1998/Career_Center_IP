{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5512fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyPDF2\n",
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0657550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pdfminer.high_level\n",
    "import pdfminer.layout\n",
    "\n",
    "with open('cv_sample.pdf', 'rb') as fh:\n",
    "    text = ''\n",
    "    for page in pdfminer.high_level.extract_pages(fh):\n",
    "        for element in page:\n",
    "            if isinstance(element, pdfminer.layout.LTTextBoxHorizontal):\n",
    "                text += element.get_text()\n",
    "    print(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the PDF file\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef467b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the text using spaCy\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract name\n",
    "import re\n",
    "name_pattern = r\"([A-Z]+\\s[A-Z]+)\"\n",
    "name = re.findall(name_pattern, text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49108c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract email\n",
    "email = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5946f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract phone number\n",
    "phone_pattern = r'(\\+\\d{2}\\s)?(\\d{1}\\s)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}'\n",
    "phone_match = re.search(phone_pattern, text)\n",
    "if phone_match:\n",
    "    phone_number = phone_match.group()\n",
    "else:\n",
    "    phone_number = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ffe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract education\n",
    "education_pattern = r\"EDUCATION\\n(.+)\"\n",
    "education = re.findall(education_pattern, text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf08b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract work experience\n",
    "def extract_work_experience(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # Create a list to store the extracted work experience\n",
    "    work_experience_list = []\n",
    "    \n",
    "    # Define a list of keywords to identify work experience sentences\n",
    "    keywords = ['work experience', 'professional experience', 'employment history', 'career highlights', 'accomplishments', 'professional background']\n",
    "    \n",
    "    # Loop through each sentence in the text\n",
    "    for sentence in sentences:\n",
    "        # Convert the sentence to lowercase and remove any whitespace\n",
    "        sentence = sentence.lower().strip()\n",
    "\n",
    "        # Check if the sentence contains any of the keywords\n",
    "        if any(keyword in sentence for keyword in keywords):\n",
    "            # Extract the relevant information from the sentence\n",
    "            doc = nlp(sentence)\n",
    "            company = None\n",
    "            title = None\n",
    "            start_date = None\n",
    "            end_date = None\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_ == 'ORG' and not ent.text.isupper():\n",
    "                    company = ent.text\n",
    "                if ent.label_ == 'TITLE' and not ent.text.isupper():\n",
    "                    title = ent.text\n",
    "                if ent.label_ == 'DATE':\n",
    "                    if not start_date:\n",
    "                        start_date = ent.text\n",
    "                    else:\n",
    "                        end_date = ent.text\n",
    "                        break\n",
    "            # Append the extracted information to the list\n",
    "            if company and title and start_date:\n",
    "                work_experience = {\n",
    "                    'company': company,\n",
    "                    'title': title,\n",
    "                    'start_date': start_date,\n",
    "                    'end_date': end_date\n",
    "                }\n",
    "                work_experience_list.append(work_experience)\n",
    "    \n",
    "    # Return the list of extracted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assuming the text is already extracted and stored in the variable `text`\n",
    "\n",
    "# regex pattern for interests\n",
    "interests_pattern = r\"Interests:(.*)\"\n",
    "\n",
    "# extract interests using regex\n",
    "interests_match = re.search(interests_pattern, text)\n",
    "\n",
    "if interests_match:\n",
    "    interests = interests_match.group(1).strip().split(\", \")\n",
    "    print(\"Interests:\", interests)\n",
    "else:\n",
    "    print(\"Interests not found\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e953b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract skills and languages\n",
    "skills_and_languages = re.findall(r'\\b([A-Z][a-z]+(?:\\s[A-Z][a-z]+)*):\\s(.+?)(?=\\n\\n|\\n[A-Z])', text, re.DOTALL)\n",
    "\n",
    "# Create a dictionary to store the skills and languages\n",
    "skills_and_languages_dict = {}\n",
    "\n",
    "# Iterate through the skills and languages tuples and add them to the dictionary\n",
    "for skill, description in skills_and_languages:\n",
    "    skills_and_languages_dict[skill] = description.strip()\n",
    "\n",
    "# Print the skills and languages dictionary\n",
    "print(\"Skills and Languages:\")\n",
    "print(skills_and_languages_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the extracted information\n",
    "   # Print the extracted information\n",
    "print('Name:', name)\n",
    "print('Email:', email)\n",
    "print('Phone:', phone_number)\n",
    "print('Education:', education)\n",
    "print('Experience:', work_experience_list)\n",
    "print('Interests:', interests)\n",
    "print('Skills and Languages:', skills_and_languages_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9baa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "this "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
